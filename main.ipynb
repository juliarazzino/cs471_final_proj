{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS471 Final Project Data Processing\n",
    "### Julia Razzino, Connor Brezenski, Michaela Kovalsky"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are designing a machine learning model to predict an individual's Big Five personality traits based on their extended Spotify listening history. First, we will import the required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/connorbrezenski/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Import statements\n",
    "import pandas as pd\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "import time\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we create a function to read in the listening history data (json) and convert it to a csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_to_csv(json_filename, csv_filename=None):\n",
    "    try:\n",
    "        if csv_filename is None:\n",
    "            csv_filename = json_filename.replace('.json', '.csv')\n",
    "        \n",
    "        with open(json_filename, encoding='utf-8') as inputfile:\n",
    "            df = pd.read_json(inputfile)\n",
    "        \n",
    "        df.to_csv(csv_filename, encoding='utf-8', index=False)\n",
    "        \n",
    "        return f\"CSV file '{csv_filename}' created successfully.\"\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        return f\"Error: The file '{json_filename}' does not exist.\"\n",
    "    except ValueError as e:\n",
    "        return f\"Error: {e}. Ensure the JSON structure is valid for conversion.\"\n",
    "    except Exception as e:\n",
    "        return f\"An unexpected error occurred: {e}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we call the function we just made and print the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file 'data/Kovalsky_Streaming_History_Audio_2014-2020.csv' created successfully.\n"
     ]
    }
   ],
   "source": [
    "result = json_to_csv('data/Kovalsky_Streaming_History_Audio_2014-2020.json')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for the Spotify Web API install and set up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\c25julia.razzino\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: spotipy in c:\\users\\c25julia.razzino\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.24.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\c25julia.razzino\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\c25julia.razzino\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\c25julia.razzino\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\c25julia.razzino\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: redis>=3.5.3 in c:\\users\\c25julia.razzino\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spotipy) (5.2.0)\n",
      "Requirement already satisfied: requests>=2.25.0 in c:\\users\\c25julia.razzino\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spotipy) (2.32.3)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in c:\\users\\c25julia.razzino\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spotipy) (2.2.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\c25julia.razzino\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\c25julia.razzino\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.25.0->spotipy) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\c25julia.razzino\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.25.0->spotipy) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\c25julia.razzino\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.25.0->spotipy) (2024.8.30)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install pandas spotipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the spotify API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace with your Spotify API credentials\n",
    "CLIENT_ID = 'ff359b48e7074fe09b99477eb78af081'         # Replace with your Client ID\n",
    "CLIENT_SECRET = 'b726f74b70a54c458a59839442f6a710' # Replace with your Client Secret\n",
    "\n",
    "# Authenticate with Spotify\n",
    "client_credentials_manager = SpotifyClientCredentials(\n",
    "    client_id=CLIENT_ID,\n",
    "    client_secret=CLIENT_SECRET\n",
    ")\n",
    "sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify path listening history file path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace with your JSON file path\n",
    "json_filename = '.\\\\data\\\\Brezenski_Streaming_History_Audio_2023-2024_8.json'\n",
    "\n",
    "# Load the JSON data into a DataFrame\n",
    "df = pd.read_json(json_filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perpare data for Spotify API call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique tracks: 5407\n"
     ]
    }
   ],
   "source": [
    "# Ensure the column name matches your data structure\n",
    "track_uri_column = 'spotify_track_uri'  # Adjust if your column name is different\n",
    "\n",
    "# Drop rows without a track URI\n",
    "df = df.dropna(subset=[track_uri_column])\n",
    "\n",
    "# Extract unique track URIs\n",
    "unique_track_uris = df[track_uri_column].unique().tolist()\n",
    "\n",
    "print(f\"Total unique tracks: {len(unique_track_uris)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionaries to hold fetched data\n",
    "track_info_dict = {}\n",
    "audio_features_dict = {}\n",
    "artist_genres_dict = {}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call track details and audio features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spotify API allows fetching up to 50 tracks per request\n",
    "BATCH_SIZE = 50\n",
    "\n",
    "for i in range(0, len(unique_track_uris), BATCH_SIZE):\n",
    "    batch_uris = unique_track_uris[i:i+BATCH_SIZE]\n",
    "    \n",
    "    # Fetch track details\n",
    "    try:\n",
    "        tracks = sp.tracks(batch_uris)['tracks']\n",
    "        for track in tracks:\n",
    "            if track:  # Check if track is not None\n",
    "                track_id = track['uri']\n",
    "                track_info_dict[track_id] = {\n",
    "                    'track_name': track['name'],\n",
    "                    'album_name': track['album']['name'],\n",
    "                    'album_release_date': track['album']['release_date'],\n",
    "                    'track_popularity': track['popularity'],\n",
    "                    'duration_ms': track['duration_ms'],\n",
    "                    'explicit': track['explicit'],\n",
    "                    'artist_ids': [artist['id'] for artist in track['artists']],\n",
    "                    'artist_names': [artist['name'] for artist in track['artists']],\n",
    "                }\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching track details for batch starting at index {i}: {e}\")\n",
    "    \n",
    "    # Fetch audio features\n",
    "    try:\n",
    "        features = sp.audio_features(batch_uris)\n",
    "        for feature in features:\n",
    "            if feature:  # Check if feature is not None\n",
    "                track_id = feature['uri']\n",
    "                audio_features_dict[track_id] = feature\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching audio features for batch starting at index {i}: {e}\")\n",
    "    \n",
    "    time.sleep(0.1)  # Adjust sleep time as necessary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetch artist's generes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique artists: 3542\n"
     ]
    }
   ],
   "source": [
    "# Collect all unique artist IDs\n",
    "all_artist_ids = set()\n",
    "for track_data in track_info_dict.values():\n",
    "    all_artist_ids.update(track_data['artist_ids'])\n",
    "\n",
    "print(f\"Total unique artists: {len(all_artist_ids)}\")\n",
    "\n",
    "# Fetch artist genres in batches\n",
    "artist_ids_list = list(all_artist_ids)\n",
    "for i in range(0, len(artist_ids_list), BATCH_SIZE):\n",
    "    batch_artist_ids = artist_ids_list[i:i+BATCH_SIZE]\n",
    "    try:\n",
    "        artists = sp.artists(batch_artist_ids)['artists']\n",
    "        for artist in artists:\n",
    "            if artist:  # Check if artist is not None\n",
    "                artist_id = artist['id']\n",
    "                artist_genres_dict[artist_id] = artist['genres']\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching artist genres for batch starting at index {i}: {e}\")\n",
    "    \n",
    "    time.sleep(0.1)  # Adjust sleep time as necessary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add dictionaries to data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert track info dict to DataFrame\n",
    "track_info_df = pd.DataFrame.from_dict(track_info_dict, orient='index')\n",
    "\n",
    "# Convert audio features dict to DataFrame\n",
    "audio_features_df = pd.DataFrame.from_dict(audio_features_dict, orient='index')\n",
    "\n",
    "# Reset index to have 'spotify_track_uri' as a column\n",
    "track_info_df = track_info_df.reset_index().rename(columns={'index': 'spotify_track_uri'})\n",
    "audio_features_df = audio_features_df.reset_index().rename(columns={'index': 'spotify_track_uri'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         spotify_track_uri  \\\n",
      "0     spotify:track:7aqfrAY2p9BUSiupwk3svU   \n",
      "1     spotify:track:7LTCmtMpf3JPfBE8gAl64z   \n",
      "2     spotify:track:0VJXWgw0GWsprapvlpbuyu   \n",
      "3     spotify:track:4M68xjcc42oxyphhzpOWXS   \n",
      "4     spotify:track:5VE6OSfJkMHyMpHaJzuUqn   \n",
      "...                                    ...   \n",
      "5402  spotify:track:688ucfDoelAC8sY7wgHCV4   \n",
      "5403  spotify:track:2wAJTrFhCnQyNSD3oUgTZO   \n",
      "5404  spotify:track:3mTpegrOwRn0oJjv4TSbEE   \n",
      "5405  spotify:track:6gbiTbclnHlmSIPfmF2zEc   \n",
      "5406  spotify:track:5A8xI7PN4WDe9e61xEdt94   \n",
      "\n",
      "                                track_name                      album_name  \\\n",
      "0     First Person Shooter (feat. J. Cole)                For All The Dogs   \n",
      "1           Turn Yo Clic Up (feat. Future)  Turn Yo Clic Up (feat. Future)   \n",
      "2                                     Okay                            Okay   \n",
      "3                             Great Gatsby                       Nostalgia   \n",
      "4                            Gimme Da Lite                   Gimme Da Lite   \n",
      "...                                    ...                             ...   \n",
      "5402                      Jesus in my life                Jesus in my life   \n",
      "5403                              Work Out  Cole World: The Sideline Story   \n",
      "5404                      Can't Get Enough  Cole World: The Sideline Story   \n",
      "5405                Gang Shit No Lame Shit                        Glockoma   \n",
      "5406                             Yeah Glo!               Ehhthang Ehhthang   \n",
      "\n",
      "     album_release_date  track_popularity  duration_ms  explicit  \\\n",
      "0            2023-10-06                74       247444      True   \n",
      "1            2023-07-14                58       230835      True   \n",
      "2            2023-12-08                43       192195      True   \n",
      "3            2023-09-15                69       146751      True   \n",
      "4            2023-12-08                55       113333      True   \n",
      "...                 ...               ...          ...       ...   \n",
      "5402         2022-02-04                41       147719     False   \n",
      "5403         2011-09-27                79       235320      True   \n",
      "5404         2011-09-27                69       225960     False   \n",
      "5405         2018-11-23                72       131600      True   \n",
      "5406         2024-04-05                75       142702      True   \n",
      "\n",
      "                                             artist_ids  \\\n",
      "0      [3TVXtAsR1Inumwj472S9r4, 6l3HvQ5sa6mXTsMTB19rO5]   \n",
      "1      [0VRj0yCOv2FXJNP47XQnx5, 1RyvyyTE3xzB2ZywiAwp0i]   \n",
      "2     [6vXTefBL93Dj5IqAWq6OTv, 5f7VJjfbwm532GiveGC0Z...   \n",
      "3                              [45TgXXqMDdF8BkjA83OM7z]   \n",
      "4      [23DYJsw4uSCguIqiTIDtcN, 6icQOAFXDZKsumw3YXyusw]   \n",
      "...                                                 ...   \n",
      "5402                           [1KTljUXZGt7HkAFFEnDBn1]   \n",
      "5403                           [6l3HvQ5sa6mXTsMTB19rO5]   \n",
      "5404   [6l3HvQ5sa6mXTsMTB19rO5, 2iojnBLj0qIMiKPvVhLnsH]   \n",
      "5405                           [0RESbWvOMyua0yuyVrztJ5]   \n",
      "5406                           [2qoQgPAilErOKCwE2Y8wOG]   \n",
      "\n",
      "                               artist_names  \n",
      "0                          [Drake, J. Cole]  \n",
      "1                           [Quavo, Future]  \n",
      "2     [French Montana, Lil Baby, ATL Jacob]  \n",
      "3                                [Rod Wave]  \n",
      "4                   [Southside, Lil Yachty]  \n",
      "...                                     ...  \n",
      "5402                            [Skema Boy]  \n",
      "5403                              [J. Cole]  \n",
      "5404                  [J. Cole, Trey Songz]  \n",
      "5405                            [Key Glock]  \n",
      "5406                             [GloRilla]  \n",
      "\n",
      "[5407 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "print(track_info_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge results into one data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge track info and audio features on 'spotify_track_uri'\n",
    "track_data_df = pd.merge(track_info_df, audio_features_df, on='spotify_track_uri', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Review columns for correctness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['spotify_track_uri', 'track_name', 'album_name', 'album_release_date',\n",
      "       'track_popularity', 'duration_ms_x', 'explicit', 'artist_ids',\n",
      "       'artist_names', 'danceability', 'energy', 'key', 'loudness', 'mode',\n",
      "       'speechiness', 'acousticness', 'instrumentalness', 'liveness',\n",
      "       'valence', 'tempo', 'type', 'id', 'uri', 'track_href', 'analysis_url',\n",
      "       'duration_ms_y', 'time_signature'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(track_data_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get genres for artists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get genres for a list of artist IDs\n",
    "def get_genres_for_artists(artist_ids):\n",
    "    genres = set()\n",
    "    for artist_id in artist_ids:\n",
    "        artist_genres = artist_genres_dict.get(artist_id, [])\n",
    "        genres.update(artist_genres)\n",
    "    return list(genres)\n",
    "\n",
    "# Apply the function to each row\n",
    "track_data_df['artist_genres'] = track_data_df['artist_ids'].apply(get_genres_for_artists)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert to strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten 'artist_ids' and 'artist_names' to strings\n",
    "track_data_df['artist_ids'] = track_data_df['artist_ids'].apply(lambda x: ', '.join(x))\n",
    "track_data_df['artist_names'] = track_data_df['artist_names'].apply(lambda x: ', '.join(x))\n",
    "track_data_df['artist_genres'] = track_data_df['artist_genres'].apply(lambda x: ', '.join(x))\n",
    "\n",
    "# Optionally, drop columns you don't need\n",
    "# track_data_df = track_data_df.drop(columns=['type', 'id', 'track_href', 'analysis_url', 'time_signature'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge data into data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the enriched track data back into the original DataFrame\n",
    "df_enriched = pd.merge(df, track_data_df, on='spotify_track_uri', how='left')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         ts    username platform  ms_played conn_country  \\\n",
      "0      2023-12-22T15:58:39Z  kingzenski      ios     109100           US   \n",
      "1      2023-12-22T15:58:40Z  kingzenski      ios       1010           US   \n",
      "2      2023-12-22T15:58:56Z  kingzenski      ios      16620           US   \n",
      "3      2023-12-22T15:59:00Z  kingzenski      ios       4050           US   \n",
      "4      2023-12-22T15:59:06Z  kingzenski      ios       5700           US   \n",
      "...                     ...         ...      ...        ...          ...   \n",
      "16909  2024-05-31T22:45:15Z  kingzenski      ios      34943           US   \n",
      "16910  2024-05-31T22:45:19Z  kingzenski      ios       3370           US   \n",
      "16911  2024-05-31T22:45:22Z  kingzenski      ios       3541           US   \n",
      "16912  2024-05-31T22:45:25Z  kingzenski      ios       2560           US   \n",
      "16913  2024-05-31T22:45:29Z  kingzenski      ios       3754           US   \n",
      "\n",
      "                           ip_addr_decrypted user_agent_decrypted  \\\n",
      "0                             172.58.125.201              unknown   \n",
      "1                             172.58.125.201              unknown   \n",
      "2                             172.58.125.201              unknown   \n",
      "3                             172.58.125.201              unknown   \n",
      "4                             172.58.125.201              unknown   \n",
      "...                                      ...                  ...   \n",
      "16909  2607:fb91:7c6:962c:352f:6466:ead:8521                 None   \n",
      "16910  2607:fb91:7c6:962c:352f:6466:ead:8521                 None   \n",
      "16911  2607:fb91:7c6:962c:352f:6466:ead:8521                 None   \n",
      "16912  2607:fb91:7c6:962c:352f:6466:ead:8521                 None   \n",
      "16913  2607:fb91:7c6:962c:352f:6466:ead:8521                 None   \n",
      "\n",
      "                 master_metadata_track_name master_metadata_album_artist_name  \\\n",
      "0      First Person Shooter (feat. J. Cole)                             Drake   \n",
      "1            Turn Yo Clic Up (feat. Future)                             Quavo   \n",
      "2                                      Okay                    French Montana   \n",
      "3                              Great Gatsby                          Rod Wave   \n",
      "4                             Gimme Da Lite                         Southside   \n",
      "...                                     ...                               ...   \n",
      "16909    Roll in Peace (feat. XXXTENTACION)                       Kodak Black   \n",
      "16910                        Jocelyn Flores                      XXXTENTACION   \n",
      "16911                            Time Today                      Moneybagg Yo   \n",
      "16912                     F.N.F. (Let's Go)                           Hitkidd   \n",
      "16913                              Ultimate                      Denzel Curry   \n",
      "\n",
      "      master_metadata_album_album_name  ... valence    tempo            type  \\\n",
      "0                     For All The Dogs  ...   0.245  163.997  audio_features   \n",
      "1       Turn Yo Clic Up (feat. Future)  ...   0.629  124.927  audio_features   \n",
      "2                                 Okay  ...   0.284  123.065  audio_features   \n",
      "3                            Nostalgia  ...   0.154  156.975  audio_features   \n",
      "4                        Gimme Da Lite  ...   0.406  144.014  audio_features   \n",
      "...                                ...  ...     ...      ...             ...   \n",
      "16909     Project Baby 2: All Grown Up  ...   0.363  140.053  audio_features   \n",
      "16910                               17  ...   0.437  134.021  audio_features   \n",
      "16911                 A Gangsta’s Pain  ...   0.327  136.994  audio_features   \n",
      "16912                F.N.F. (Let's Go)  ...   0.647  157.144  audio_features   \n",
      "16913                         Ultimate  ...   0.750  112.865  audio_features   \n",
      "\n",
      "                           id                                   uri  \\\n",
      "0      7aqfrAY2p9BUSiupwk3svU  spotify:track:7aqfrAY2p9BUSiupwk3svU   \n",
      "1      7LTCmtMpf3JPfBE8gAl64z  spotify:track:7LTCmtMpf3JPfBE8gAl64z   \n",
      "2      0VJXWgw0GWsprapvlpbuyu  spotify:track:0VJXWgw0GWsprapvlpbuyu   \n",
      "3      4M68xjcc42oxyphhzpOWXS  spotify:track:4M68xjcc42oxyphhzpOWXS   \n",
      "4      5VE6OSfJkMHyMpHaJzuUqn  spotify:track:5VE6OSfJkMHyMpHaJzuUqn   \n",
      "...                       ...                                   ...   \n",
      "16909  40oKW22ZNNkEdZLJTScaQI  spotify:track:40oKW22ZNNkEdZLJTScaQI   \n",
      "16910  7m9OqQk4RVRkw9JJdeAw96  spotify:track:7m9OqQk4RVRkw9JJdeAw96   \n",
      "16911  0YrKSfpvflYnLSBd4Jtu6J  spotify:track:0YrKSfpvflYnLSBd4Jtu6J   \n",
      "16912  1vrFJDrysqmsNAgyjBzx4f  spotify:track:1vrFJDrysqmsNAgyjBzx4f   \n",
      "16913  6R0GRYk2vs2XuBVemYK5YZ  spotify:track:6R0GRYk2vs2XuBVemYK5YZ   \n",
      "\n",
      "                                              track_href  \\\n",
      "0      https://api.spotify.com/v1/tracks/7aqfrAY2p9BU...   \n",
      "1      https://api.spotify.com/v1/tracks/7LTCmtMpf3JP...   \n",
      "2      https://api.spotify.com/v1/tracks/0VJXWgw0GWsp...   \n",
      "3      https://api.spotify.com/v1/tracks/4M68xjcc42ox...   \n",
      "4      https://api.spotify.com/v1/tracks/5VE6OSfJkMHy...   \n",
      "...                                                  ...   \n",
      "16909  https://api.spotify.com/v1/tracks/40oKW22ZNNkE...   \n",
      "16910  https://api.spotify.com/v1/tracks/7m9OqQk4RVRk...   \n",
      "16911  https://api.spotify.com/v1/tracks/0YrKSfpvflYn...   \n",
      "16912  https://api.spotify.com/v1/tracks/1vrFJDrysqms...   \n",
      "16913  https://api.spotify.com/v1/tracks/6R0GRYk2vs2X...   \n",
      "\n",
      "                                            analysis_url  duration_ms_y  \\\n",
      "0      https://api.spotify.com/v1/audio-analysis/7aqf...         247444   \n",
      "1      https://api.spotify.com/v1/audio-analysis/7LTC...         230836   \n",
      "2      https://api.spotify.com/v1/audio-analysis/0VJX...         192195   \n",
      "3      https://api.spotify.com/v1/audio-analysis/4M68...         146752   \n",
      "4      https://api.spotify.com/v1/audio-analysis/5VE6...         113333   \n",
      "...                                                  ...            ...   \n",
      "16909  https://api.spotify.com/v1/audio-analysis/40oK...         213132   \n",
      "16910  https://api.spotify.com/v1/audio-analysis/7m9O...         119133   \n",
      "16911  https://api.spotify.com/v1/audio-analysis/0YrK...         136900   \n",
      "16912  https://api.spotify.com/v1/audio-analysis/1vrF...         137580   \n",
      "16913  https://api.spotify.com/v1/audio-analysis/6R0G...         189974   \n",
      "\n",
      "       time_signature                                      artist_genres  \n",
      "0                   4  north carolina hip hop, rap, hip hop, canadian...  \n",
      "1                   4  rap, atl hip hop, melodic rap, hip hop, trap, ...  \n",
      "2                   4  rap, atl hip hop, hip hop, pop rap, atl trap, ...  \n",
      "3                   4                                        florida rap  \n",
      "4                   4      rap, atl hip hop, melodic rap, atl trap, trap  \n",
      "...               ...                                                ...  \n",
      "16909               4  miami hip hop, florida drill, rap, florida rap...  \n",
      "16910               4                        rap, miami hip hop, emo rap  \n",
      "16911               4  rap, tennessee hip hop, memphis hip hop, trap,...  \n",
      "16912               4                  southern hip hop, memphis hip hop  \n",
      "16913               4  miami hip hop, drill, rap, underground hip hop...  \n",
      "\n",
      "[16914 rows x 48 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_enriched)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create output file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enriched data saved to data/your_streaming_history_enriched.csv\n"
     ]
    }
   ],
   "source": [
    "# Replace with your desired output file path\n",
    "output_csv_filename = 'data/your_streaming_history_enriched.csv'\n",
    "\n",
    "# Save to CSV\n",
    "df_enriched.to_csv(output_csv_filename, index=False)\n",
    "\n",
    "print(f\"Enriched data saved to {output_csv_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: Kovalsky_2014-2020.csv\n",
      "Extracted username: Kovalsky\n",
      "Processing file: Razzino_2023-2024.csv\n",
      "Extracted username: Razzino\n",
      "Processing file: Blalock_2023-2024.csv\n",
      "Extracted username: Blalock\n",
      "Processing file: Brezenski_2023-2024.csv\n",
      "Extracted username: Brezenski\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/64/s8x7jmb54wq7ldv0c_5hb_wm0000gn/T/ipykernel_57820/196408419.py:23: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# Define the data directory\n",
    "data_dir = 'data/processed/'  # Replace with your actual directory path\n",
    "\n",
    "# Get a list of all CSV files\n",
    "csv_files = glob.glob(os.path.join(data_dir, '*.csv'))\n",
    "\n",
    "# Initialize a list to hold data from each user\n",
    "user_data_list = []\n",
    "\n",
    "for file in csv_files:\n",
    "    # Extract the username from the filename\n",
    "    filename = os.path.basename(file)\n",
    "    name_part = os.path.splitext(filename)[0]\n",
    "    name_parts = name_part.split('_')\n",
    "    username = '_'.join(name_parts[:-1])  # Joins all parts except the last one (assuming date is last)\n",
    "    \n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(file)\n",
    "    \n",
    "    # Add the username column\n",
    "    df['username'] = username\n",
    "    \n",
    "    # Debugging: Print out the filename and extracted username\n",
    "    print(f'Processing file: {filename}')\n",
    "    print(f'Extracted username: {username}')\n",
    "    \n",
    "    # Append to the list\n",
    "    user_data_list.append(df)\n",
    "\n",
    "# Combine all user data into a single DataFrame\n",
    "df = pd.concat(user_data_list, ignore_index=True)\n",
    "\n",
    "# Proceed with the rest of your data processing...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ts                                       0\n",
      "username                                 0\n",
      "platform                                 0\n",
      "ms_played                                0\n",
      "conn_country                             0\n",
      "ip_addr_decrypted                     1777\n",
      "user_agent_decrypted                 10977\n",
      "master_metadata_track_name               0\n",
      "master_metadata_album_artist_name        0\n",
      "master_metadata_album_album_name         0\n",
      "spotify_track_uri                        0\n",
      "episode_name                         58125\n",
      "episode_show_name                    58125\n",
      "spotify_episode_uri                  58125\n",
      "reason_start                            22\n",
      "reason_end                            1793\n",
      "shuffle                                  0\n",
      "skipped                               3796\n",
      "offline                                  0\n",
      "offline_timestamp                        0\n",
      "incognito_mode                           0\n",
      "track_name                             158\n",
      "album_name                             158\n",
      "album_release_date                       0\n",
      "track_popularity                         0\n",
      "duration_ms_x                            0\n",
      "explicit                                 0\n",
      "artist_ids                               0\n",
      "artist_names                           158\n",
      "danceability                             2\n",
      "energy                                   2\n",
      "key                                      2\n",
      "loudness                                 2\n",
      "mode                                     2\n",
      "speechiness                              2\n",
      "acousticness                             2\n",
      "instrumentalness                         2\n",
      "liveness                                 2\n",
      "valence                                  2\n",
      "tempo                                    2\n",
      "type                                     2\n",
      "id                                       2\n",
      "uri                                      2\n",
      "track_href                               2\n",
      "analysis_url                             2\n",
      "duration_ms_y                            2\n",
      "time_signature                           2\n",
      "artist_genres                         4603\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Decide on a strategy: drop or impute missing values\n",
    "#df = df.dropna(subset=['essential_column1', 'essential_column2'])  # Replace with actual column names\n",
    "\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "irrelevant_columns = ['ts', 'platform', 'conn_country', 'ip_addr_decrypted', 'user_agent_decrypted',\n",
    "                      'spotify_track_uri', 'episode_name', 'episode_show_name', 'spotify_episode_uri',\n",
    "                      'reason_start', 'reason_end', 'offline_timestamp', 'track_href', 'analysis_url',\n",
    "                      'uri', 'id', 'track_name', 'album_name', 'album_release_date', 'duration_ms_y',\n",
    "                      'type', 'master_metadata_track_name', 'master_metadata_album_artist_name',\n",
    "                      'master_metadata_album_album_name']\n",
    "df = df.drop(columns=irrelevant_columns, errors='ignore')  # Use errors='ignore' in case some columns are missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'float' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/groupby/groupby.py:1824\u001b[0m, in \u001b[0;36mGroupBy.apply\u001b[0;34m(self, func, include_groups, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1823\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1824\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_apply_general\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selected_obj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1825\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1826\u001b[0m         \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj, Series)\n\u001b[1;32m   1827\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_selection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1828\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_selected_obj\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_obj_with_exclusions\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m   1829\u001b[0m     ):\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/groupby/groupby.py:1885\u001b[0m, in \u001b[0;36mGroupBy._python_apply_general\u001b[0;34m(self, f, data, not_indexed_same, is_transform, is_agg)\u001b[0m\n\u001b[1;32m   1859\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1860\u001b[0m \u001b[38;5;124;03mApply function f in python space\u001b[39;00m\n\u001b[1;32m   1861\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1883\u001b[0m \u001b[38;5;124;03m    data after applying f\u001b[39;00m\n\u001b[1;32m   1884\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1885\u001b[0m values, mutated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_grouper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_groupwise\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m not_indexed_same \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/groupby/ops.py:919\u001b[0m, in \u001b[0;36mBaseGrouper.apply_groupwise\u001b[0;34m(self, f, data, axis)\u001b[0m\n\u001b[1;32m    918\u001b[0m group_axes \u001b[38;5;241m=\u001b[39m group\u001b[38;5;241m.\u001b[39maxes\n\u001b[0;32m--> 919\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mutated \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_indexed_like(res, group_axes, axis):\n",
      "Cell \u001b[0;32mIn[13], line 7\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Aggregate genres per user\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m user_genres \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124musername\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124martist_genres_list\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: [genre \u001b[38;5;28;01mfor\u001b[39;00m sublist \u001b[38;5;129;01min\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m genre \u001b[38;5;129;01min\u001b[39;00m sublist])\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Apply MultiLabelBinarizer\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[13], line 7\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Aggregate genres per user\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m user_genres \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124musername\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124martist_genres_list\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: [genre \u001b[38;5;28;01mfor\u001b[39;00m sublist \u001b[38;5;129;01min\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m genre \u001b[38;5;129;01min\u001b[39;00m sublist])\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Apply MultiLabelBinarizer\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'float' object is not iterable",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124martist_genres_list\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124martist_genres\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Aggregate genres per user\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m user_genres \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43musername\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43martist_genres_list\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mgenre\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msublist\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgenre\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msublist\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Apply MultiLabelBinarizer\u001b[39;00m\n\u001b[1;32m     10\u001b[0m mlb \u001b[38;5;241m=\u001b[39m MultiLabelBinarizer()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/groupby/generic.py:230\u001b[0m, in \u001b[0;36mSeriesGroupBy.apply\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(\n\u001b[1;32m    225\u001b[0m     _apply_docs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemplate\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    226\u001b[0m         \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseries\u001b[39m\u001b[38;5;124m\"\u001b[39m, examples\u001b[38;5;241m=\u001b[39m_apply_docs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseries_examples\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    227\u001b[0m     )\n\u001b[1;32m    228\u001b[0m )\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series:\n\u001b[0;32m--> 230\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/groupby/groupby.py:1846\u001b[0m, in \u001b[0;36mGroupBy.apply\u001b[0;34m(self, func, include_groups, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1830\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1831\u001b[0m                 message\u001b[38;5;241m=\u001b[39m_apply_groupings_depr\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1832\u001b[0m                     \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1835\u001b[0m                 stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m   1836\u001b[0m             )\n\u001b[1;32m   1837\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   1838\u001b[0m         \u001b[38;5;66;03m# gh-20949\u001b[39;00m\n\u001b[1;32m   1839\u001b[0m         \u001b[38;5;66;03m# try again, with .apply acting as a filtering\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1843\u001b[0m         \u001b[38;5;66;03m# fails on *some* columns, e.g. a numeric operation\u001b[39;00m\n\u001b[1;32m   1844\u001b[0m         \u001b[38;5;66;03m# on a string grouper column\u001b[39;00m\n\u001b[0;32m-> 1846\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_apply_general\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_obj_with_exclusions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1848\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/groupby/groupby.py:1885\u001b[0m, in \u001b[0;36mGroupBy._python_apply_general\u001b[0;34m(self, f, data, not_indexed_same, is_transform, is_agg)\u001b[0m\n\u001b[1;32m   1850\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m   1851\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_python_apply_general\u001b[39m(\n\u001b[1;32m   1852\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1857\u001b[0m     is_agg: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1858\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NDFrameT:\n\u001b[1;32m   1859\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1860\u001b[0m \u001b[38;5;124;03m    Apply function f in python space\u001b[39;00m\n\u001b[1;32m   1861\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1883\u001b[0m \u001b[38;5;124;03m        data after applying f\u001b[39;00m\n\u001b[1;32m   1884\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1885\u001b[0m     values, mutated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_grouper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_groupwise\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1886\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m not_indexed_same \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1887\u001b[0m         not_indexed_same \u001b[38;5;241m=\u001b[39m mutated\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/groupby/ops.py:919\u001b[0m, in \u001b[0;36mBaseGrouper.apply_groupwise\u001b[0;34m(self, f, data, axis)\u001b[0m\n\u001b[1;32m    917\u001b[0m \u001b[38;5;66;03m# group might be modified\u001b[39;00m\n\u001b[1;32m    918\u001b[0m group_axes \u001b[38;5;241m=\u001b[39m group\u001b[38;5;241m.\u001b[39maxes\n\u001b[0;32m--> 919\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mutated \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_indexed_like(res, group_axes, axis):\n\u001b[1;32m    921\u001b[0m     mutated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[13], line 7\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      4\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124martist_genres_list\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124martist_genres\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Aggregate genres per user\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m user_genres \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124musername\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124martist_genres_list\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: [genre \u001b[38;5;28;01mfor\u001b[39;00m sublist \u001b[38;5;129;01min\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m genre \u001b[38;5;129;01min\u001b[39;00m sublist])\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Apply MultiLabelBinarizer\u001b[39;00m\n\u001b[1;32m     10\u001b[0m mlb \u001b[38;5;241m=\u001b[39m MultiLabelBinarizer()\n",
      "Cell \u001b[0;32mIn[13], line 7\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      4\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124martist_genres_list\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124martist_genres\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Aggregate genres per user\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m user_genres \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124musername\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124martist_genres_list\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: [genre \u001b[38;5;28;01mfor\u001b[39;00m sublist \u001b[38;5;129;01min\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m genre \u001b[38;5;129;01min\u001b[39;00m sublist])\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Apply MultiLabelBinarizer\u001b[39;00m\n\u001b[1;32m     10\u001b[0m mlb \u001b[38;5;241m=\u001b[39m MultiLabelBinarizer()\n",
      "\u001b[0;31mTypeError\u001b[0m: 'float' object is not iterable"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "# Split genres and create a list per row\n",
    "df['artist_genres_list'] = df['artist_genres'].str.split(', ')\n",
    "\n",
    "# Aggregate genres per user\n",
    "user_genres = df.groupby('username')['artist_genres_list'].apply(lambda x: [genre for sublist in x for genre in sublist])\n",
    "\n",
    "# Apply MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "genre_dummies = pd.DataFrame(mlb.fit_transform(user_genres), columns=mlb.classes_, index=user_genres.index)\n",
    "\n",
    "key_dummies = pd.get_dummies(df['key'], prefix='key')\n",
    "\n",
    "# Aggregate per user\n",
    "user_keys = df.groupby('username')[key_dummies.columns].mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the aggregation functions for each feature\n",
    "agg_functions = {\n",
    "    'ms_played': 'sum',\n",
    "    'skipped': 'mean',\n",
    "    'shuffle': 'mean',\n",
    "    'offline': 'mean',\n",
    "    'incognito_mode': 'mean',\n",
    "    'track_popularity': ['mean', 'std'],\n",
    "    'explicit': 'mean',\n",
    "    'danceability': ['mean', 'std'],\n",
    "    'energy': ['mean', 'std'],\n",
    "    'loudness': ['mean', 'std'],\n",
    "    'mode': 'mean',\n",
    "    'speechiness': ['mean', 'std'],\n",
    "    'acousticness': ['mean', 'std'],\n",
    "    'instrumentalness': ['mean', 'std'],\n",
    "    'liveness': ['mean', 'std'],\n",
    "    'valence': ['mean', 'std'],\n",
    "    'tempo': ['mean', 'std'],\n",
    "    'time_signature': ['mean', 'std']\n",
    "}\n",
    "\n",
    "# Aggregate per user\n",
    "user_agg = df.groupby('username').agg(agg_functions)\n",
    "\n",
    "# Flatten MultiIndex columns\n",
    "user_agg.columns = ['_'.join(col).strip() for col in user_agg.columns.values]\n",
    "\n",
    "# Combine user_agg, genre_dummies, and user_keys\n",
    "user_data = user_agg.join(genre_dummies, how='left')\n",
    "user_data = user_data.join(user_keys, how='left')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
